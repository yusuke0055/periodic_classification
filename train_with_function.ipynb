{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle as pkl\n",
    "import copy\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sys\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "53\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "all_class = os.listdir(\"../Images/periodic/all\")\n",
    "print(len(all_class))\n",
    "\n",
    "remove_classes = [\"stone-wall4.o\"]\n",
    "test_classes   = [\"B5CC4D9964F342BD.o\"]\n",
    "all_class = [ i for i in all_class if i not in remove_classes ]\n",
    "\n",
    "train_target_classes = [ i for i in all_class if i not in test_classes ]\n",
    "test_target_classes =  [ i for i in all_class if i in test_classes ]\n",
    "\n",
    "print(len(train_target_classes))\n",
    "print(len(test_target_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_packs = utils.get_paths(train_target_classes)\n",
    "test_packs  = utils.get_paths(test_target_classes)\n",
    "train_transforms = utils.data_transformer_torch_train()\n",
    "test_transforms  = utils.data_transformer_torch_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_train = utils.Img_Dataset(file_list=train_packs[0],transform=train_transforms,labels=train_packs[1],class_labels=train_packs[2])\n",
    "datasets_test  = utils.Img_Dataset(file_list=test_packs[0] ,transform=test_transforms,labels=test_packs[1],class_labels=test_packs[2])\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(datasets_train, batch_size=8, shuffle=True,num_workers=8)\n",
    "dataloader_test  = torch.utils.data.DataLoader(datasets_test , batch_size=8, shuffle=False,num_workers=8)\n",
    "\n",
    "dataloaders  = {\"train\":dataloader_train,\"val\":dataloader_test }\n",
    "dataset_sizes ={\"train\":len(datasets_train),\"val\":len(datasets_test)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.vgg16(pretrained=True)\n",
    "model.classifier = nn.Sequential(\n",
    "        nn.Linear(25088,100),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(100,1) ,nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "---train---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yusuke/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5312 ,ACC:0.6987\n",
      "---val---\n",
      "val Loss: 0.7598 ,ACC:0.5000\n",
      "Epoch 2/10\n",
      "----------\n",
      "---train---\n",
      "train Loss: 0.5040 ,ACC:0.7411\n",
      "---val---\n",
      "val Loss: 0.0596 ,ACC:1.0000\n",
      "Epoch 3/10\n",
      "----------\n",
      "---train---\n",
      "train Loss: 0.3655 ,ACC:0.8296\n",
      "---val---\n",
      "val Loss: 0.2546 ,ACC:0.9500\n",
      "Epoch 4/10\n",
      "----------\n",
      "---train---\n",
      "train Loss: 0.3758 ,ACC:0.8390\n",
      "---val---\n",
      "val Loss: 0.3982 ,ACC:1.0000\n",
      "Epoch 5/10\n",
      "----------\n",
      "---train---\n",
      "train Loss: 0.3748 ,ACC:0.8230\n",
      "---val---\n",
      "val Loss: 0.5686 ,ACC:0.5000\n",
      "Epoch 6/10\n",
      "----------\n",
      "---train---\n",
      "train Loss: 0.2465 ,ACC:0.9011\n",
      "---val---\n",
      "val Loss: 0.0032 ,ACC:1.0000\n",
      "Epoch 7/10\n",
      "----------\n",
      "---train---\n",
      "   736/  1062\r"
     ]
    }
   ],
   "source": [
    "model,loss_dict,acc_dict = utils.training_model(dataloaders,dataset_sizes,model,criterion,\n",
    "                     optimizer,scheduler,num_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
